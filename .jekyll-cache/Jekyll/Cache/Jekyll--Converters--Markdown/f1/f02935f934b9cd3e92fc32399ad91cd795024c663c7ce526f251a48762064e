I"<p>In this tutorial, we will be working with Amazon SageMaker to build, train and deploy a machine learning model using XGBoost algorithm.</p>

<p>We will be working with a bank dataset and we will try to predict whether a customer will enroll for a certificate of deposit or CD.</p>

<p>In order to work, we need to have AWS account.</p>

<p>We will follow following steps: 1) Create a notebook 2) Prepare our data 3) Train the model to learn from the training dataset 4) Deploy the model 5) Evaluate performance</p>

<p>Once you login to AWS SageMaker, create instance of a notebook, IAM role and select S3 bucket.</p>

<p>In Jupyter, create a new conda_python3 notebook.</p>

<p>Below code imports the required libraries amd defines environmental variables needed to prepare the data, train the ML Model, and deploy ML Model

</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># import libraries
import boto3, re, sys, math, json, os, sagemaker, urllib.request
from sagemaker import get_execution_role
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image
from IPython.display import display
from time import gmtime, strftime
from sagemaker.predictor import csv_serializer

# Define IAM role
role = get_execution_role()
prefix = 'sagemaker/DEMO-xgboost-dm'
my_region = boto3.session.Session().region_name # set the region of the instance

# this line automatically looks for the XGBoost image URI and builds an XGBoost container.
xgboost_container = sagemaker.image_uris.retrieve("xgboost", my_region, "latest")

print("Success - the MySageMakerInstance is in the " + my_region + " region. You will use the " + xgboost_container + " container for your SageMaker endpoint.")
</code></pre></div></div>
:ET